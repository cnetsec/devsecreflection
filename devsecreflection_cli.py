import os
import google.generativeai as genai
from InquirerPy import inquirer
from rich import print

# Seguran√ßa: exige vari√°vel de ambiente com a API Key
def config_gemini(api_key: str):
    genai.configure(api_key=api_key)

def select_available_model():
    preferred_models = [
        "models/gemini-1.5-flash-latest",
        "models/gemini-1.5-pro-latest",
        "models/gemini-pro"
    ]
    try:
        print("üîé Verificando modelos dispon√≠veis na sua API Key...")
        available_models = [
            m.name for m in genai.list_models()
            if "generateContent" in m.supported_generation_methods
        ]
        if not available_models:
            print("‚ùå Nenhum modelo com suporte a 'generateContent' foi encontrado para sua API Key.")
            return None
        for model_name in preferred_models:
            if model_name in available_models:
                print(f"‚úÖ Modelo selecionado (otimizado para Free Tier): {model_name}")
                return model_name
        fallback_model = available_models[0]
        print(f"‚ö†Ô∏è Usando fallback: {fallback_model}")
        return fallback_model
    except Exception as e:
        print(f"‚ùå Erro ao listar modelos: {e}")
        return None

def build_prompt(context):
    return f"""
Voc√™ √© um assistente de seguran√ßa que analisa decis√µes de desenvolvimento com foco em seguran√ßa, privacidade e boas pr√°ticas.

Com base nas respostas abaixo, forne√ßa dicas claras e pr√°ticas de seguran√ßa para o desenvolvedor revisar com seu time e PO:

- O que est√° sendo desenvolvido: {context['tipo']}
- Objetivo: {context['objetivo']}
- P√∫blico-alvo: {context['usuario']}
- Envolve IA? {context['usa_ia']}
- Riscos identificados: {", ".join(context['riscos']) if context['riscos'] else "Nenhum"}

Liste recomenda√ß√µes em t√≥picos, separando por:

1. Valida√ß√µes importantes
2. Controles de seguran√ßa recomendados
3. Alertas sobre uso de IA (se aplic√°vel)
4. Pontos para valida√ß√£o com o PO
"""

def generate_analysis(context, api_key):
    config_gemini(api_key)
    model_name = select_available_model()
    if not model_name:
        return "‚ùå N√£o foi poss√≠vel selecionar um modelo v√°lido."
    model = genai.GenerativeModel(model_name)
    prompt = build_prompt(context)
    response = model.generate_content(prompt)
    return response.text.strip()

def main():
    print("
" + "="*43)
    print("üß† Bem-vindo ao DevSecReflection (CLI Seguro)")
    print("-------------------------------------------")
    print("Aux√≠lio ao dev com seguran√ßa em primeiro lugar.")
    print("Entradas s√£o todas por menus guiados.")
    print("="*43 + "
")

    context = {
        "tipo": inquirer.select(
            message="üß± O que voc√™ vai desenvolver?",
            choices=["API", "Integra√ß√£o com IA", "Front-end", "Backend", "Banco de Dados", "Autentica√ß√£o", "Outros"]
        ).execute(),
        "objetivo": inquirer.select(
            message="üéØ Qual √© o objetivo principal?",
            choices=["Nova funcionalidade", "Corre√ß√£o", "Melhoria", "Refatora√ß√£o", "Prototipa√ß√£o"]
        ).execute(),
        "usuario": inquirer.select(
            message="üë• Quem vai usar essa funcionalidade?",
            choices=["Usu√°rio final", "Admin", "Servi√ßo interno", "API externa", "Outros"]
        ).execute(),
        "usa_ia": inquirer.select(
            message="ü§ñ Essa entrega envolve uso de IA?",
            choices=["Yes", "No"]
        ).execute(),
        "riscos": inquirer.checkbox(
            message="üõ°Ô∏è Quais riscos de seguran√ßa voc√™ enxerga?",
            choices=["Exposi√ß√£o de dados", "Inje√ß√£o", "Acesso indevido", "Disponibilidade", "Nenhum identificado"]
        ).execute()
    }

    api_key = inquirer.secret(message="üîê Cole aqui sua Gemini API Key").execute()

    print("‚è≥ Gerando an√°lise com base nas respostas...")
    result = generate_analysis(context, api_key)

    print("
" + "="*40)
    print("üìå Resultado da An√°lise:")
    print("="*40)
    print(result)

if __name__ == "__main__":
    main()